{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test suite for Project 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "* `../data/train.csv`\n",
    "* `../data/test.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = '../data/train.csv'\n",
    "test_path  = '../data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Long, run only if necessary\n",
    "train_data = load_csv_data(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Long, run only if necessary\n",
    "test_data = load_csv_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data as pickles for more efficient reloading\n",
    "# Only run once to generate the pickle !\n",
    "pickle.dump(test_data, open( 'test.p', 'wb' ))\n",
    "pickle.dump(train_data, open( 'train.p', 'wb' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading the pickle back \n",
    "train_data = pickle.load(open( 'train.p', 'rb' ))\n",
    "test_data = pickle.load(open( 'test.p', 'rb' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory\n",
    "\n",
    "* Describe / Discover the data\n",
    "* Describe / Characterise the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 250000 samples.\n"
     ]
    }
   ],
   "source": [
    "## Data dimensions\n",
    "print(\"There are {} samples.\".format(len(train_data[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is defined as a set $D = \\{ (y_i, \\mathbf{x}_i, w_i) \\}$ with :\n",
    "* $y_i \\in \\{+1,-1\\}$ is the label (signal = `+1` or noise = `-1`)\n",
    "* $\\mathbf{x}_i \\in \\!R^d$ is a $d$-dimensional feature vector\n",
    "* $w_i \\in \\!R^+$ is a non-negative weight\n",
    "\n",
    "Note that $\\sum_{i\\in\\mathcal{S}} w_i = N_s$ and $\\sum_{i\\in\\mathcal{B}} w_i = N_b$ which are the *expected total number of signal and background events (resp.)*. This gives an estimate of how many events we should expect to classify for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The feature vector shape is \n",
    "train_data[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which means we have d features :\n",
    "d = train_data[2].shape[1]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = train_data[0]\n",
    "labels  = train_data[1]\n",
    "x_train = train_data[2]\n",
    "\n",
    "if(labels.ndim<2):\n",
    "    labels = np.expand_dims(labels, axis=1) # expand the labels as array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about the features :\n",
    "\n",
    "* Variables are floating point unless specified otherwise.\n",
    "* All azimuthal φ angles are in radian in the [−π, +π[ range.\n",
    "* Energy, mass, momentum are all in GeV\n",
    "* All other variables are unit less\n",
    "* **Undefined values are `-999.0`**\n",
    "\n",
    "There are `primitive` (prefixed with `PRI`) values, directly measured from the collision, and `derived` (prefixed with `DER`) values which were computed from the primitive values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 17\n"
     ]
    }
   ],
   "source": [
    "PRI_features = x_train[:,:13]\n",
    "DER_features = x_train[:,13:]\n",
    "print(len(PRI_features[0]), len(DER_features[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "* Split test / train\n",
    "* Clean useless features\n",
    "* [Scale / process data](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/) (e.g. scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data is perfectly clean ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.245599999999996"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = [x for x in x_train if not -999. in x]\n",
    "len(clean_data)/len(x_train)*100 # percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data is clean in the primitive or derived classes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.245599999999996"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRI_clean_data = [x for x in PRI_features if not -999. in x]\n",
    "len(PRI_clean_data)/len(PRI_features)*100 # percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.0172"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DER_clean_data = [x for x in DER_features if not -999. in x]\n",
    "len(DER_clean_data)/len(DER_features)*100 # percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentage is almost the same ! This means there was not a lot of treatment error, using only `PRI` or only `DER` data won't make the data cleaner (but it might help reduce the complexity of the model ;) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there classes that contain a high probability of dirty data ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "per_feature_stats = []\n",
    "for i in range(d):\n",
    "    sz = len(x_train[:,i])\n",
    "    clean_ft = [x for x in x_train[:,i] if (x != -999.)] # c pa bo ... :'(\n",
    "    per_feature_stats.append(len(clean_ft) / sz * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[84.75439999999999,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 29.0172,\n",
       " 29.0172,\n",
       " 29.0172,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 29.0172,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 100.0,\n",
       " 60.0348,\n",
       " 60.0348,\n",
       " 60.0348,\n",
       " 29.0172,\n",
       " 29.0172,\n",
       " 29.0172,\n",
       " 100.0]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_feature_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives a pretty good indication of the features that should be pruned from the data ! Notably :\n",
    "* `x_train[:, 4: 7]` (which are resp. `DER_deltaeta_jet_jet`, `DER_mass_jet_jet`, `DER_prodeta_jet_jet`)\n",
    "* `x_train[:,12]` (which is `DER_lep_eta_centrality`)\n",
    "* `x_train[:,26:29]` (which is the `PRI_jet_subleading_{pt,eta,phi}`)\n",
    "\n",
    "We can also consider removing `x_train[:,23:26]` (`PRI_jet_leading_{pt,eta,phi}`) which only has ~60% clean data ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_idx(ranges):\n",
    "    clean_idx = np.asarray([list(range(i,j)) for i,j in ranges])\n",
    "    return [item for sublist in clean_idx for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only 100% clean data\n",
    "ranges = [(1,4), (7,12), (13,23), (29,30)]\n",
    "keep_idx = build_idx(ranges)\n",
    "x_train_full_clean = x_train[:,keep_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With feature 1 and 23-26\n",
    "ranges = [(0,4), (7,12), (13,26), (29,30)]\n",
    "keep_idx = build_idx(ranges)\n",
    "x_train_partial_clean = x_train[:,keep_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With features 1-3\n",
    "ranges = [(1,4)]\n",
    "keep_idx = build_idx(ranges)\n",
    "x_train_small_features = x_train[:,keep_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of the sets, and expand the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n",
      "(250000, 19)\n",
      "(250000, 23)\n",
      "(250000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_train_full_clean.shape)\n",
    "print(x_train_partial_clean.shape)\n",
    "print(x_train_small_features.shape)\n",
    "\n",
    "tx_train = np.c_[np.ones((labels.shape[0], 1)), x_train]\n",
    "tx_train_full_clean = np.c_[np.ones((y.shape[0], 1)), x_train_full_clean]\n",
    "tx_train_partial_clean = np.c_[np.ones((y.shape[0], 1)), x_train_partial_clean]\n",
    "tx_train_small_features = np.c_[np.ones((y.shape[0], 1)), x_train_small_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a very small set for testing the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_small_set = 1000\n",
    "\n",
    "small_tx_train = tx_train_full_clean[0:param_small_set, :]\n",
    "small_labels = labels[0:param_small_set]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "* **Train** the model with the different learning algorithms\n",
    "    * `least_squares`\n",
    "    * `least_squares_GD`\n",
    "    * `least_squares_SGD`\n",
    "    * `ridge_regression`\n",
    "    * `logistic_regression`\n",
    "    * `reg_logistic_regression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.73105858,  0.88079708],\n",
       "       [ 0.88079708,  0.95257413]])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([[1.0, 2.0], [2.0, 3.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_gradient_descent(y, tx, lambda_=0.1):\n",
    "    # init parameters\n",
    "    max_iter = 10000\n",
    "    gamma = 0.5\n",
    "    w_init = np.zeros((tx.shape[1], 1))\n",
    "\n",
    "    w, loss = reg_logistic_regression(y, tx, lambda_, w_init, max_iter, gamma)\n",
    "       \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -1509.70087874]\n",
      " [-123990.71021196]\n",
      " [-123493.45640896]\n",
      " [ -25471.0604693 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philippe/Desktop/ML_Projects/project1/src/auxiliary.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-t))\n"
     ]
    }
   ],
   "source": [
    "tx = small_tx_train\n",
    "y = small_labels\n",
    " \n",
    "w = logistic_regression_gradient_descent(y, tx)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auxiliary import *\n",
    "\n",
    "def compute_classification_error(y, tx, w):\n",
    "    s = sigmoid(tx.dot(w))\n",
    "    result = np.ones(y.shape[0])\n",
    "    for idx, y_n in enumerate(y):\n",
    "        #print(idx, y_n, s[idx])\n",
    "        if y_n == 1 and s[idx] >= 0.5:\n",
    "            result[idx] = 0.0\n",
    "        elif y_n == -1 and s[idx] < 0.5:\n",
    "            result[idx] = 0.0\n",
    "    if(result.sum()/y.shape[0] > 0.7):\n",
    "        #print(s)\n",
    "        #print(tx.dot(w))\n",
    "        print(w)\n",
    "    return result.sum()/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, tx, k_indices, k, lambda_):\n",
    "    \"\"\"return the loss of logistic regression.\"\"\"\n",
    "    # get k'th subgroup in test, others in train\n",
    "    k_indices = k_indices.astype(int)\n",
    "    k_indices_train = np.array([])\n",
    "    \n",
    "    for i in range(k_indices.shape[0]):\n",
    "        if i != k:\n",
    "            k_indices_train = np.append(k_indices_train, k_indices[i])\n",
    "    \n",
    "    k_indices_test = k_indices[k]\n",
    "    \n",
    "    tx_train = tx[k_indices_train.astype(int)]\n",
    "    y_train = y[k_indices_train.astype(int)]\n",
    "    \n",
    "    tx_test = tx[k_indices_test.astype(int)]\n",
    "    y_test = y[k_indices_test.astype(int)]\n",
    "\n",
    "    # logistic regression\n",
    "    w = logistic_regression_gradient_descent(y_train, tx_train, lambda_)\n",
    "    \n",
    "    # calculate the loss for train and test data\n",
    "    loss_tr = compute_classification_error(y_train,tx_train,w)\n",
    "    loss_te = compute_classification_error(y_test,tx_test,w)\n",
    "\n",
    "    return loss_tr, loss_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots import cross_validation_visualization\n",
    "\n",
    "def cross_validation_demo(y, x):\n",
    "    verbose = True\n",
    "    seed = 1\n",
    "    k_fold = 4\n",
    "    lambdas = np.logspace(-4, 0, 30)\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    \n",
    "    print(\"Current run: {N} samples, {f} features\".format(N=x.shape[0], f=x.shape[1]))\n",
    "\n",
    "\n",
    "    # define lists to store the loss of training data and test data\n",
    "    final_losses_tr = []\n",
    "    final_losses_te = []\n",
    "\n",
    "    # cross validation: TODO\n",
    "    for idx, lambda_ in enumerate(lambdas):\n",
    "        losses_tr = []\n",
    "        losses_te = []\n",
    "        for k in range(k_fold):\n",
    "            loss_tr, loss_te = cross_validation(y, x, k_indices, k, lambda_)\n",
    "            losses_tr.append(loss_tr)\n",
    "            losses_te.append(loss_te)\n",
    "        final_losses_tr.append(np.mean(losses_tr))\n",
    "        final_losses_te.append(np.mean(losses_te))\n",
    "        if verbose:\n",
    "            print(\"Current lambda: {i} out of {j}\".format(i=idx, j=len(lambdas)))\n",
    "    \n",
    "    cross_validation_visualization(lambdas, final_losses_tr, final_losses_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current run: 1000 samples, 20 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philippe/Desktop/ML_Projects/project1/src/auxiliary.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-t))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lambda: 0 out of 30\n",
      "Current lambda: 1 out of 30\n",
      "Current lambda: 2 out of 30\n",
      "Current lambda: 3 out of 30\n",
      "Current lambda: 4 out of 30\n",
      "Current lambda: 5 out of 30\n",
      "Current lambda: 6 out of 30\n",
      "Current lambda: 7 out of 30\n",
      "Current lambda: 8 out of 30\n",
      "Current lambda: 9 out of 30\n",
      "Current lambda: 10 out of 30\n",
      "Current lambda: 11 out of 30\n",
      "Current lambda: 12 out of 30\n",
      "Current lambda: 13 out of 30\n",
      "Current lambda: 14 out of 30\n",
      "Current lambda: 15 out of 30\n",
      "Current lambda: 16 out of 30\n",
      "Current lambda: 17 out of 30\n",
      "Current lambda: 18 out of 30\n",
      "Current lambda: 19 out of 30\n",
      "Current lambda: 20 out of 30\n",
      "Current lambda: 21 out of 30\n",
      "Current lambda: 22 out of 30\n",
      "Current lambda: 23 out of 30\n",
      "Current lambda: 24 out of 30\n",
      "Current lambda: 25 out of 30\n",
      "Current lambda: 26 out of 30\n",
      "Current lambda: 27 out of 30\n",
      "Current lambda: 28 out of 30\n",
      "Current lambda: 29 out of 30\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEaCAYAAAA7YdFPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e2c6438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from auxiliary import *\n",
    "tx = small_tx_train\n",
    "y = small_labels\n",
    "cross_validation_demo(y,tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "* **Test** the model with the weights computed from the different learning algorithms to find the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validate\n",
    "\n",
    "* the hyperparameters for each algorithm\n",
    "    * `least_squares` \n",
    "    * `least_squares_GD` -> `gamma`\n",
    "    * `least_squares_SGD` -> `gamma`, `batch_size`\n",
    "    * `ridge_regression` -> `lambda_`\n",
    "    * `logistic_regression` -> `gamma`\n",
    "    * `reg_logistic_regression` -> `lambda_`, `gamma`\n",
    "* Also, if we use other features (e.g. polynomial), we should CV those as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "* Plot the train / test accuracies for the best set of algorithm + parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
